# run_parallel_mps.py
import os, json, time, multiprocessing as mp
from collections import defaultdict

import numpy as np
from tqdm import tqdm
import torch

from session import SessionManager
import onnx

ROOT = os.path.dirname(__file__)
ITER = 1000                    # ëª¨ë¸ë‹¹ ì¶”ë¡  íšŸìˆ˜

###############################################################################
# 1) ëª¨ë¸ ëª©ë¡
###############################################################################
with open(os.path.join(ROOT, "models.json")) as f:
    model_list = json.load(f)["models"]
if not model_list:
    raise RuntimeError("models.json ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤")

###############################################################################
# 2) ëª¨ë¸ë³„ SM ì§€ë¶„(%)
###############################################################################
# model_shares = { m : int(100/len(model_list)) for m in model_list }  # ê· ë“± ë¶„ë°°
# print("ëª¨ë¸ë³„ MPS ì§€ë¶„ ì„¤ì •:", model_shares)
# model_shares = {               # version 1.0 not bad
#     "mask_rcnn" : 50,
#     "bert" : 5,
#     "resnet50" : 20,
#     "mobilenet_v2" : 10,
#     "inception_v4" : 10,
#     "squeezenet1_0" : 5, 
# }
model_shares = {               # ì›í•˜ëŠ” ë¹„ìœ¨ë¡œ ìˆ˜ì •
    "mask_rcnn" : 45,
    "bert" : 3,
    "resnet50" : 12,
    "mobilenet_v2" : 10,
    "inception_v4" : 20,
    "squeezenet1_0" : 10, 
}
# DEFAULT_SHARE = 20

###############################################################################
# 3) Loop í¬í•¨ ì—¬ë¶€ â†’ Copy-Stream ì˜µì…˜ ê²°ì •
###############################################################################
def contains_loop(path: str) -> bool:
    return any(n.op_type == "Loop" for n in onnx.load(path).graph.node)

def provider_for(model):
    mpth = os.path.join("/", "models", f"{model}.onnx")
    if contains_loop(mpth):
        return ("CUDAExecutionProvider", {"device_id": 0})
    return ("CUDAExecutionProvider", {"device_id": 0,
                                      "do_copy_in_default_stream": 0})

providers = {m: provider_for(m) for m in model_list}

###############################################################################
# 4) ì›Œì»¤ í”„ë¡œì„¸ìŠ¤
###############################################################################
def worker(model, iters, share_pct, q):
    # â‘  ê° í”„ë¡œì„¸ìŠ¤ë§ˆë‹¤ MPS ì§€ë¶„ ì„¤ì •
    os.environ["CUDA_MPS_ACTIVE_THREAD_PERCENTAGE"] = str(share_pct)

    # â‘¡ ì„¸ì…˜ ë¡œë“œ & ì›Œë°ì—…
    SessionManager.fetch_model(model, providers[model], batch_size=1)
    SessionManager.run_model(model)          # warm-up

    lat = []
    for k in range(iters):
        torch.cuda.nvtx.range_push(f"{model}_iter{k}")
        out = SessionManager.run_model(model)
        torch.cuda.nvtx.range_pop()

        ms = float(out.split("output:")[1].split("ms")[0].strip())
        lat.append(ms)

    q.put((model, lat))       # ê²°ê³¼ ë°˜í™˜

###############################################################################
# 5) ë©”ì¸ â€“ í”„ë¡œì„¸ìŠ¤ ë³‘ë ¬ ì‹¤í–‰
###############################################################################
if __name__ == "__main__":
    mp.set_start_method("spawn")             # CUDA ì•ˆì „ëª¨ë“œ
    q = mp.Queue()
    procs = []
    t0 = time.time()                         # --------- â¬…ï¸ ì „ì²´ íƒ€ì´ë¨¸ ì‹œì‘
    torch.cuda.cudart().cudaProfilerStart()

    for m in model_list:
        pct = model_shares[m]
        p = mp.Process(target=worker, args=(m, ITER, pct, q))
        p.start()
        procs.append(p)

    # ì§„í–‰ë°”
    for p in tqdm(procs, desc="ëª¨ë¸ í”„ë¡œì„¸ìŠ¤ ê°€ë™"):
        p.join()

    torch.cuda.cudart().cudaProfilerStop()

    wall_elapsed = time.time() - t0          # --------- â¬…ï¸ ì „ì²´ íƒ€ì´ë¨¸ ì¢…ë£Œ

    # ê²°ê³¼ ì§‘ê³„
    lat_dict = defaultdict(list)
    while not q.empty():
        name, lst = q.get()
        lat_dict[name].extend(lst)

    total_jobs = len(model_list) * ITER
    throughput = total_jobs / wall_elapsed

    print(f"\nâœ… {total_jobs} íšŒ ì¶”ë¡  ì™„ë£Œ â€“ {wall_elapsed:.2f}s, "
          f"{throughput:.1f} infer/s\n")

    for m in model_list:
        l = lat_dict[m]
        if l:
            print(f"ğŸ”¹ {m:20s}  í‰ê·  {np.mean(l):7.2f} ms | Ïƒ {np.std(l):6.2f} ms | "
                  f"SM {model_shares[m]} %")
        else:
            print(f"âš ï¸ {m}: latency ìˆ˜ì§‘ ì‹¤íŒ¨")